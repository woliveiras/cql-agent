"""
Agente de IA para Reparos Residenciais
Agente bÃ¡sico que responde perguntas sobre reparos residenciais usando modelos locais
"""

from langchain_ollama import ChatOllama
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from pydantic import BaseModel, Field
from typing import Optional, List
from enum import Enum


class ConversationState(Enum):
    """Estados da conversaÃ§Ã£o"""
    NEW_PROBLEM = "new_problem"
    WAITING_FEEDBACK = "waiting_feedback"
    RESOLVED = "resolved"
    MAX_ATTEMPTS = "max_attempts"


class RepairAgent:
    """Agente especializado em reparos residenciais com acompanhamento de tentativas"""
    
    def __init__(
        self,
        model_name: str = "qwen2.5:3b",
        temperature: float = 0.3,
        num_predict: int = 500,
        base_url: str = "http://localhost:11434",
        max_attempts: int = 3
    ):
        """
        Inicializa o agente de reparos residenciais
        
        Args:
            model_name: Nome do modelo Ollama a ser usado
            temperature: Controla a criatividade das respostas (0.0 a 1.0)
            num_predict: Limita tokens de resposta
            base_url: URL do servidor Ollama, localhost:11434 por padrÃ£o
            max_attempts: NÃºmero mÃ¡ximo de tentativas antes de sugerir profissional
        """
        self.llm = ChatOllama(
            model=model_name,
            temperature=temperature,
            num_predict=num_predict,
            base_url=base_url
        )
        
        self.max_attempts = max_attempts
        self.conversation_history: List = []
        self.current_attempt = 0
        self.state = ConversationState.NEW_PROBLEM
        
        self.base_system_prompt = """VocÃª Ã© um assistente especializado em reparos residenciais.
Seu objetivo Ã© ajudar as pessoas a resolver pequenos problemas em suas casas.

IMPORTANTE: Responda de forma DIRETA e CONCISA, sem mostrar seu raciocÃ­nio interno.

VocÃª deve:
- Fornecer instruÃ§Ãµes claras e passo a passo
- Alertar sobre possÃ­veis perigos e precauÃ§Ãµes de seguranÃ§a quando necessÃ¡rio
- Ser educado, prestativo e paciente
- Usar linguagem simples e acessÃ­vel
- Responder de forma objetiva e rÃ¡pida"""
    
    def _get_system_prompt(self) -> str:
        """Retorna o prompt de sistema apropriado baseado no estado"""
        prompt = self.base_system_prompt
        
        if self.state == ConversationState.NEW_PROBLEM:
            prompt += """\n\nAPÃ“S fornecer a soluÃ§Ã£o completa, SEMPRE termine sua resposta com:

"O problema foi resolvido? Responda com 'sim' ou 'nÃ£o'."

NUNCA sugira chamar um profissional na primeira tentativa."""
        
        elif self.state == ConversationState.WAITING_FEEDBACK:
            if self.current_attempt < self.max_attempts:
                prompt += f"""\n\nO usuÃ¡rio tentou a soluÃ§Ã£o anterior mas nÃ£o funcionou (tentativa {self.current_attempt}/{self.max_attempts}).
ForneÃ§a uma NOVA abordagem diferente ou dicas adicionais.
Seja encorajador e termine perguntando:

"Essa soluÃ§Ã£o funcionou? Responda com 'sim' ou 'nÃ£o'." """
            else:
                prompt += f"""\n\nO usuÃ¡rio jÃ¡ tentou {self.max_attempts} vezes sem sucesso.
AgradeÃ§a o esforÃ§o e sugira educadamente buscar um profissional qualificado.
Explique que alguns problemas podem ser mais complexos e necessitam equipamento ou experiÃªncia especializada."""
        
        return prompt
    
    def _is_positive_feedback(self, message: str) -> bool:
        """Detecta se a mensagem do usuÃ¡rio indica sucesso"""
        message_lower = message.lower().strip()
        
        # Respostas diretas
        if message_lower in ['sim', 's', 'yes', 'y']:
            return True
        
        # Frases positivas
        positive_phrases = [
            'funcionou', 'deu certo', 'consegui', 'resolveu', 'resolvido',
            'obrigado', 'valeu', 'sucesso', 'estÃ¡ funcionando'
        ]
        return any(phrase in message_lower for phrase in positive_phrases)
    
    def _is_negative_feedback(self, message: str) -> bool:
        """Detecta se a mensagem do usuÃ¡rio indica falha"""
        message_lower = message.lower().strip()
        
        # Respostas diretas
        if message_lower in ['nÃ£o', 'nao', 'n', 'no']:
            return True
        
        # Frases negativas
        negative_phrases = [
            'nÃ£o funcionou', 'nÃ£o deu', 'nÃ£o consegui', 'ainda nÃ£o',
            'continua', 'nÃ£o resolveu', 'problema persiste', 'nÃ£o estÃ¡',
            'ainda estÃ¡', 'persiste'
        ]
        return any(phrase in message_lower for phrase in negative_phrases)
    
    def chat(self, user_message: str) -> str:
        """
        Processa uma mensagem do usuÃ¡rio e retorna a resposta do agente
        
        Args:
            user_message: Pergunta ou solicitaÃ§Ã£o do usuÃ¡rio
            
        Returns:
            Resposta do agente
        """
        # Atualiza o estado baseado no feedback
        if self.state == ConversationState.WAITING_FEEDBACK:
            if self._is_positive_feedback(user_message):
                self.state = ConversationState.RESOLVED
                return """ğŸ‰ Que Ã³timo que deu certo! Fico feliz em ter ajudado!

Se precisar de ajuda com outro reparo, Ã© sÃ³ me chamar. Boa sorte e atÃ© a prÃ³xima! ğŸ‘‹"""
            
            elif self._is_negative_feedback(user_message):
                self.current_attempt += 1
                if self.current_attempt >= self.max_attempts:
                    self.state = ConversationState.MAX_ATTEMPTS
            else:
                # Feedback ambÃ­guo - pede clarificaÃ§Ã£o
                return """âš ï¸ NÃ£o entendi sua resposta. 

O problema foi resolvido? Por favor, responda apenas com 'sim' ou 'nÃ£o'."""
        
        # Se chegou ao mÃ¡ximo de tentativas
        if self.state == ConversationState.MAX_ATTEMPTS:
            return f"""Entendo sua frustraÃ§Ã£o. JÃ¡ tentamos {self.max_attempts} abordagens diferentes e o problema persiste.

Neste ponto, recomendo que vocÃª procure um profissional qualificado. Alguns problemas podem ser mais complexos do que parecem e podem necessitar:
- Ferramentas especializadas
- Conhecimento tÃ©cnico avanÃ§ado
- InspeÃ§Ã£o presencial para diagnÃ³stico correto

VocÃª fez um bom esforÃ§o tentando resolver sozinho! Se tiver outro problema no futuro, estarei aqui para ajudar. ğŸ”§"""
        
        # Adiciona mensagem do usuÃ¡rio ao histÃ³rico
        self.conversation_history.append(HumanMessage(content=user_message))
        
        # Prepara as mensagens para o LLM
        messages = [
            SystemMessage(content=self._get_system_prompt()),
            *self.conversation_history
        ]
        
        # ObtÃ©m resposta do modelo
        response = self.llm.invoke(messages)
        
        # Adiciona resposta ao histÃ³rico
        self.conversation_history.append(AIMessage(content=response.content))
        
        # Atualiza estado para aguardar feedback apÃ³s primeira resposta
        if self.state == ConversationState.NEW_PROBLEM:
            self.state = ConversationState.WAITING_FEEDBACK
            self.current_attempt = 1
        
        return response.content
    
    def reset(self):
        """Reinicia o agente para um novo problema"""
        self.conversation_history = []
        self.current_attempt = 0
        self.state = ConversationState.NEW_PROBLEM


class RepairQuery(BaseModel):
    """Modelo para validaÃ§Ã£o de consultas de reparo"""
    question: str = Field(..., description="Pergunta sobre reparo residencial")
    urgency: Optional[str] = Field(None, description="NÃ­vel de urgÃªncia: baixa, mÃ©dia, alta")
    location: Optional[str] = Field(None, description="Local do problema (ex: cozinha, banheiro)")


def main():
    """FunÃ§Ã£o principal para interaÃ§Ã£o via linha de comando"""
    print("=" * 60)
    print("ğŸ”§ CQL AI Agent - Assistente de Reparos Residenciais")
    print("=" * 60)
    print("\nInicializando o agente...")
    
    try:
        agent = RepairAgent(max_attempts=3)
        print("\n\nâœ… Agente inicializado com sucesso!")
        print("\nğŸ’¡ Dica: O agente tentarÃ¡ ajudÃ¡-lo atÃ© 3 vezes antes de sugerir um profissional")
        print("\nğŸ“ Comandos: 'sair' para encerrar | 'novo' para um novo problema\n")
        
        while True:
            user_input = input("\nğŸ‘¤ VocÃª: ").strip()
            
            if not user_input:
                continue
            
            # Comandos especiais
            if user_input.lower() in ['sair', 'exit', 'quit']:
                print("\nğŸ‘‹ AtÃ© logo! Boa sorte com seus reparos!")
                break
            
            if user_input.lower() in ['novo', 'new', 'reiniciar', 'reset']:
                agent.reset()
                print("\nğŸ”„ Agente reiniciado! Pronto para um novo problema.")
                continue
            
            # Processar mensagem
            print("\nğŸ¤– Agente: Processando...", end="\r")
            response = agent.chat(user_input)
            print("ğŸ¤– Agente:", response)
            
            # Se o problema foi resolvido, oferecer reiniciar
            if agent.state == ConversationState.RESOLVED or agent.state == ConversationState.MAX_ATTEMPTS:
                print("\nğŸ’¬ Digite 'novo' para relatar outro problema ou 'sair' para encerrar.")
            
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ AtÃ© logo!")
    except Exception as e:
        print(f"\nâŒ Erro: {e}")
        print("\nâš ï¸  Certifique-se de que o Ollama estÃ¡ rodando:")
        print("   docker-compose up -d")
        print("   docker exec -it ollama ollama pull qwen2.5:3b")


if __name__ == "__main__":
    main()
