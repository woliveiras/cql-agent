"""
Agente de IA para Reparos Residenciais
Agente com RAG e busca web que responde perguntas sobre reparos residenciais
usando modelos locais, base de conhecimento em PDFs e busca na internet
"""

from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from pydantic import BaseModel, Field
from typing import Optional, List
from enum import Enum
import os

from .prompts import (
    BASE_SYSTEM_PROMPT,
    NEW_PROBLEM_PROMPT,
    get_waiting_feedback_prompt,
    get_max_attempts_prompt,
    SUCCESS_MESSAGE,
    get_max_attempts_message,
    AMBIGUOUS_FEEDBACK_MESSAGE
)

from agents.rag import VectorStoreManager, DocumentRetriever
from agents.tools import WebSearchTool
from agents.llm import LLMFactory
from api.logging_config import get_logger

# Logger para o agente
logger = get_logger(__name__, component="repair_agent")


class ConversationState(Enum):
    """Estados da conversa√ß√£o"""
    NEW_PROBLEM = "new_problem"
    WAITING_FEEDBACK = "waiting_feedback"
    RESOLVED = "resolved"
    MAX_ATTEMPTS = "max_attempts"


class RepairAgent:
    """Agente especializado em reparos residenciais com RAG, busca web e acompanhamento de tentativas"""

    def __init__(
        self,
        model_name: Optional[str] = None,
        temperature: Optional[float] = None,
        num_predict: Optional[int] = None,
        base_url: Optional[str] = None,
        max_attempts: int = 3,
        use_rag: bool = True,
        use_web_search: bool = True,
        chroma_db_path: str = "./chroma_db"
    ):
        """
        Inicializa o agente de reparos residenciais

        Args:
            model_name: Nome do modelo a ser usado (usa padr√£o do provedor se None)
            temperature: Controla a criatividade das respostas (0.0 a 1.0, usa padr√£o se None)
            num_predict: Limita tokens de resposta (usa padr√£o se None)
            base_url: URL do servidor (apenas para Ollama, usa OLLAMA_BASE_URL se None)
            max_attempts: N√∫mero m√°ximo de tentativas antes de sugerir profissional
            use_rag: Se True, usa RAG para buscar documentos relevantes
            use_web_search: Se True, usa busca web quando RAG n√£o encontra informa√ß√µes
            chroma_db_path: Caminho para o banco de dados ChromaDB
        """
        llm_kwargs = {}
        if base_url:
            llm_kwargs["base_url"] = base_url
        
        self.llm = LLMFactory.create_llm(
            model=model_name,
            temperature=temperature,
            max_tokens=num_predict,
            **llm_kwargs
        )

        self.max_attempts = max_attempts
        self.conversation_history: List = []
        self.current_attempt = 0
        self.state = ConversationState.NEW_PROBLEM
        self.use_rag = use_rag
        self.use_web_search = use_web_search

        # Inicializa RAG se dispon√≠vel
        self.retriever: Optional[DocumentRetriever] = None
        if use_rag and os.path.exists(chroma_db_path):
            try:
                vectorstore_manager = VectorStoreManager(
                    persist_directory=chroma_db_path
                )
                # Carrega o vectorstore existente
                vectorstore = vectorstore_manager.load_vectorstore()
                if vectorstore is None:
                    raise ValueError("N√£o foi poss√≠vel carregar o vector store")

                self.retriever = DocumentRetriever(
                    vectorstore_manager=vectorstore_manager,
                    k=3,
                    relevance_threshold=0.8
                )
                logger.info("RAG inicializado com sucesso")
            except Exception as e:
                logger.warning(f"RAG n√£o dispon√≠vel: {e}")
                self.retriever = None
        elif use_rag:
            logger.warning(
                f"Base de conhecimento n√£o encontrada",
                extra={"chroma_db_path": chroma_db_path}
            )
            logger.info("Execute: uv run scripts/setup_rag.py")

        # Inicializa Web Search se habilitado
        self.web_search: Optional[WebSearchTool] = None
        if use_web_search:
            try:
                self.web_search = WebSearchTool(max_results=3, region="br-pt")
                logger.info("Busca web inicializada com sucesso")
            except Exception as e:
                logger.warning(f"Busca web n√£o dispon√≠vel: {e}")
                self.web_search = None

    def _get_system_prompt(
        self,
        rag_context: Optional[str] = None,
        web_context: Optional[str] = None
    ) -> str:
        """
        Retorna o prompt de sistema apropriado baseado no estado

        Args:
            rag_context: Contexto da base de conhecimento (PDFs)
            web_context: Contexto da busca web (internet)
        """
        prompt = BASE_SYSTEM_PROMPT

        # Adiciona contexto do RAG se dispon√≠vel
        if rag_context:
            prompt += f"\n\n## üìö Informa√ß√µes da Base de Conhecimento (PDFs):\n{rag_context}\n"
            prompt += "\nUse essas informa√ß√µes dos manuais para fornecer uma resposta precisa.\n"

        # Adiciona contexto da web se dispon√≠vel
        if web_context:
            prompt += f"\n\n## üåê Informa√ß√µes da Internet:\n{web_context}\n"
            prompt += "\nUse essas informa√ß√µes atualizadas da internet como refer√™ncia adicional.\n"

        if self.state == ConversationState.NEW_PROBLEM:
            prompt += NEW_PROBLEM_PROMPT

        elif self.state == ConversationState.WAITING_FEEDBACK:
            if self.current_attempt < self.max_attempts:
                prompt += get_waiting_feedback_prompt(self.current_attempt, self.max_attempts)
            else:
                prompt += get_max_attempts_prompt(self.max_attempts)

        return prompt

    def _is_positive_feedback(self, message: str) -> bool:
        """Detecta se a mensagem do usu√°rio indica sucesso"""
        message_lower = message.lower().strip()

        # Primeiro verificar se h√° nega√ß√£o na mensagem
        has_negation = any(neg in message_lower for neg in ['n√£o', 'nao', 'nope', 'no'])

        # Se h√° nega√ß√£o, n√£o √© positivo
        if has_negation:
            return False

        # Respostas diretas positivas
        if message_lower in ['sim', 's', 'yes', 'y', 'ok']:
            return True

        # Frases positivas (somente se n√£o houver nega√ß√£o)
        positive_phrases = [
            'funcionou', 'deu certo', 'consegui', 'resolveu', 'resolvido',
            'obrigado', 'valeu', 'sucesso', 'est√° funcionando', 'perfeito',
            '√≥timo', 'excelente'
        ]
        return any(phrase in message_lower for phrase in positive_phrases)

    def _is_negative_feedback(self, message: str) -> bool:
        """Detecta se a mensagem do usu√°rio indica falha"""
        message_lower = message.lower().strip()

        # Respostas diretas
        if message_lower in ['n√£o', 'nao', 'n', 'no']:
            return True

        # Frases negativas
        negative_phrases = [
            'n√£o funcionou', 'n√£o deu', 'n√£o consegui', 'ainda n√£o',
            'continua', 'n√£o resolveu', 'problema persiste', 'n√£o est√°',
            'ainda est√°', 'persiste'
        ]
        return any(phrase in message_lower for phrase in negative_phrases)

    def chat(self, user_message: str) -> str:
        """
        Processa uma mensagem do usu√°rio e retorna a resposta do agente
        Complexidade justificada: m√°quina de estados com m√∫ltiplos fluxos

        Args:
            user_message: Pergunta ou solicita√ß√£o do usu√°rio

        Returns:
            Resposta do agente
        """
        # Se chegou ao m√°ximo de tentativas ou problema resolvido,
        # verificar se √© uma nova pergunta ("n√£o" √© um feedback)
        if self.state in [ConversationState.MAX_ATTEMPTS, ConversationState.RESOLVED]:
            # Se n√£o √© feedback simples (sim/n√£o), considerar como nova pergunta
            if not (self._is_positive_feedback(user_message) or self._is_negative_feedback(user_message)):
                # Reset para novo problema
                self.reset()
                # Continua processamento normal abaixo

        # Atualiza o estado baseado no feedback
        if self.state == ConversationState.WAITING_FEEDBACK:
            if self._is_positive_feedback(user_message):
                self.state = ConversationState.RESOLVED
                return SUCCESS_MESSAGE

            elif self._is_negative_feedback(user_message):
                self.current_attempt += 1
                if self.current_attempt >= self.max_attempts:
                    self.state = ConversationState.MAX_ATTEMPTS
                # Se ainda h√° tentativas, marcar que precisa de nova solu√ß√£o
                else:
                    # Estado continua WAITING_FEEDBACK mas precisamos de nova resposta
                    pass
            else:
                # Feedback amb√≠guo - pede clarifica√ß√£o
                return AMBIGUOUS_FEEDBACK_MESSAGE

        # Se chegou ao m√°ximo de tentativas (e n√£o resetou acima)
        if self.state == ConversationState.MAX_ATTEMPTS:
            return get_max_attempts_message(self.max_attempts)

        # Log de processamento
        logger.debug("Processando mensagem do usu√°rio")

        # 1. Busca contexto relevante no RAG (apenas para novas perguntas)
        rag_context = None
        web_context = None

        if self.retriever and self.state == ConversationState.NEW_PROBLEM:
            try:
                rag_context, has_relevant = self.retriever.retrieve_and_format(user_message)
                if has_relevant:
                    logger.info("RAG: informa√ß√µes relevantes encontradas na base de conhecimento")
            except Exception as e:
                logger.error(f"Erro ao buscar documentos no RAG: {e}", exc_info=True)
                rag_context = None

        # 2. Se RAG n√£o encontrou nada, busca na web (fallback)
        if not rag_context and self.web_search and self.state == ConversationState.NEW_PROBLEM:
            try:
                logger.info("Buscando informa√ß√µes na internet...")
                web_context = self.web_search.search(user_message)
                if web_context:
                    logger.info("Web Search: informa√ß√µes atualizadas encontradas")
                else:
                    logger.warning("Web Search: nenhuma informa√ß√£o relevante encontrada")
            except Exception as e:
                logger.error(f"Erro na busca web: {e}", exc_info=True)
                web_context = None

        # Adiciona mensagem do usu√°rio ao hist√≥rico
        self.conversation_history.append(HumanMessage(content=user_message))

        # Prepara as mensagens para o LLM
        messages = [
            SystemMessage(content=self._get_system_prompt(
                rag_context=rag_context,
                web_context=web_context
            )),
            *self.conversation_history
        ]

        # Obt√©m resposta do modelo
        response = self.llm.invoke(messages)

        # Adiciona resposta ao hist√≥rico
        self.conversation_history.append(AIMessage(content=response.content))

        response_text = response.content

        # Atualiza estado para aguardar feedback ap√≥s primeira resposta
        if self.state == ConversationState.NEW_PROBLEM:
            self.state = ConversationState.WAITING_FEEDBACK
            self.current_attempt = 1

        # Para tentativas subsequentes (WAITING_FEEDBACK), tamb√©m garantir a pergunta
        elif self.state == ConversationState.WAITING_FEEDBACK and self.current_attempt < self.max_attempts:
            feedback_question = "\n\nEssa solu√ß√£o funcionou? Responda com 'sim' ou 'n√£o'."

            # Se a resposta n√£o termina com a pergunta, adicionar
            if not response_text.rstrip().endswith(("'sim' ou 'n√£o'.", "'sim' ou 'n√£o'?", "sim' ou 'n√£o'.")):
                response_text += feedback_question

        return response_text

    def reset(self):
        """Reinicia o agente para um novo problema"""
        self.conversation_history = []
        self.current_attempt = 0
        self.state = ConversationState.NEW_PROBLEM


class RepairQuery(BaseModel):
    """Modelo para valida√ß√£o de consultas de reparo"""
    question: str = Field(..., description="Pergunta sobre reparo residencial")
    urgency: Optional[str] = Field(None, description="N√≠vel de urg√™ncia: baixa, m√©dia, alta")
    location: Optional[str] = Field(None, description="Local do problema (ex: cozinha, banheiro)")


def main():
    """Fun√ß√£o principal para intera√ß√£o via linha de comando
    Complexidade justificada: CLI com m√∫ltiplas op√ß√µes e fluxos"""
    print("=" * 60)
    print("üîß CQL AI Agent - Assistente de Reparos Residenciais")
    print("=" * 60)
    print("\nInicializando o agente...")

    try:
        agent = RepairAgent(max_attempts=3, use_rag=True, use_web_search=True)
        print("\n‚úÖ Agente inicializado com sucesso!")

        # Mostra status do RAG
        if agent.retriever:
            print("üìö RAG ativo - usando base de conhecimento em PDFs")
        else:
            print("‚ö†Ô∏è  RAG desativado")

        # Mostra status da busca web
        if agent.web_search:
            print("üåê Busca web ativa - usando DuckDuckGo como fallback")
        else:
            print("‚ö†Ô∏è  Busca web desativada")

        print("\nüí° O agente busca primeiro nos PDFs, depois na internet se necess√°rio")
        print("üí° Tentar√° ajud√°-lo at√© 3 vezes antes de sugerir um profissional")
        print("\nüìù Comandos: 'sair' para encerrar | 'novo' para um novo problema\n")

        while True:
            user_input = input("\nüë§ Voc√™: ").strip()

            if not user_input:
                continue

            # Comandos especiais
            if user_input.lower() in ['sair', 'exit', 'quit']:
                print("\nüëã At√© logo! Boa sorte com seus reparos!")
                break

            if user_input.lower() in ['novo', 'new', 'reiniciar', 'reset']:
                agent.reset()
                print("\nüîÑ Agente reiniciado! Pronto para um novo problema.")
                continue

            # Processar mensagem
            response = agent.chat(user_input)
            print("ü§ñ Agente:", response)

            # Se o problema foi resolvido, oferecer reiniciar
            if agent.state == ConversationState.RESOLVED or agent.state == ConversationState.MAX_ATTEMPTS:
                print("\nüí¨ Digite 'novo' para relatar outro problema ou 'sair' para encerrar.")

    except KeyboardInterrupt:
        print("\n\nüëã At√© logo!")
    except Exception as e:
        print(f"\n‚ùå Erro: {e}")
        print("\n‚ö†Ô∏è  Certifique-se de que o Ollama est√° rodando:")
        print("   docker-compose up -d")
        print("   docker exec -it ollama ollama pull qwen2.5:3b")
        print("   docker exec -it ollama ollama pull nomic-embed-text")


if __name__ == "__main__":
    main()
