# ğŸ”§ Agente de IA para Reparos Residenciais

Agente de IA especializado em ajudar com pequenos reparos residenciais, construÃ­do com LangChain, Ollama e Python.

## ğŸ“‹ Fases do Projeto

### Fase 1 - Agente BÃ¡sico âœ…

Agente bÃ¡sico que responde perguntas usando modelo LLM local.

### Fase 2 - RAG âœ…

Sistema de recuperaÃ§Ã£o de informaÃ§Ãµes de PDFs com ChromaDB.

### Fase 3 - Web Search âœ…

Busca web com DuckDuckGo como fallback quando RAG nÃ£o encontra informaÃ§Ãµes.

### Fase 4 - OpenWebUI + API REST âœ…

Interface web via OpenWebUI com API Flask documentada (Swagger).

### âœ¨ Funcionalidades

#### Fase 1 (Agente BÃ¡sico)

- ğŸ¤– Chat interativo para perguntas sobre reparos
- ğŸ  Especializado em problemas residenciais
- âš ï¸ Alertas de seguranÃ§a quando necessÃ¡rio
- ğŸ’¡ InstruÃ§Ãµes passo a passo
- ğŸ”’ 100% local e privado (usando Ollama)
- ğŸ”„ Sistema de tentativas (atÃ© 3 tentativas antes de sugerir profissional)
- âœ… ValidaÃ§Ã£o de feedback com respostas "sim" ou "nÃ£o"
- ğŸ“ HistÃ³rico de conversaÃ§Ã£o mantido para contexto
- ğŸ¯ DetecÃ§Ã£o automÃ¡tica de sucesso/falha

#### Fase 2 (RAG)

- ğŸ“š Base de conhecimento a partir de PDFs
- ğŸ” Busca semÃ¢ntica em documentos
- ğŸ’¾ Armazenamento vetorial com ChromaDB
- ğŸ¯ Respostas baseadas em manuais especÃ­ficos
- âš¡ Embeddings locais com Ollama

#### Fase 3 (Web Search)

- ğŸŒ Busca web com DuckDuckGo
- ğŸ”„ Fallback automÃ¡tico: RAG â†’ Web â†’ LLM
- ğŸ†“ Completamente gratuito (sem API keys)
- ğŸ‡§ğŸ‡· Resultados em portuguÃªs (regiÃ£o br-pt)

#### Fase 4 (API + OpenWebUI)

- ğŸŒ API REST com Flask
- ğŸ“– DocumentaÃ§Ã£o Swagger automÃ¡tica
- ğŸ”Œ Pipe Function para OpenWebUI
- ğŸ³ Docker Compose para deploy completo
- ğŸ”„ Gerenciamento de sessÃµes
- ğŸ¨ Interface web moderna
- ğŸ”’ Privacidade mantida (DuckDuckGo nÃ£o rastreia)

## ğŸš€ Como usar

### 1. PrÃ©-requisitos

- Python 3.10+
- Docker e Docker Compose
- UV (gerenciador de pacotes Python)

### 2. Iniciar o Ollama

```bash
# Subir o container do Ollama
docker-compose up -d

# Baixar os modelos (primeira vez)
docker exec -it ollama ollama pull qwen2.5:3b
docker exec -it ollama ollama pull nomic-embed-text
```

### 2.5. Configurar RAG (Opcional - Fase 2)

```bash
# 1. Adicionar PDFs na pasta pdfs/
# Coloque manuais sobre reparos residenciais

# 2. Processar PDFs e criar base de conhecimento
uv run scripts/setup_rag.py

# Isso irÃ¡ criar o banco vetorial em chroma_db/
```

### 3. Instalar dependÃªncias

```bash
uv sync
```

### 4. Executar o agente

#### OpÃ§Ã£o 1: CLI (Linha de Comando)

```bash
# Ativar o ambiente virtual (opcional, uv faz isso automaticamente)
source .venv/bin/activate

# Executar o agente
uv run agent.py
```

#### OpÃ§Ã£o 2: API REST (Fase 4)

```bash
# Iniciar API Flask
uv run python -m api.app

# Acessar documentaÃ§Ã£o Swagger
# http://localhost:5000/docs

# Testar API
uv run python test_api.py
```

#### OpÃ§Ã£o 3: Docker Compose (Deploy Completo)

```bash
# Iniciar todos os serviÃ§os (Ollama + API + OpenWebUI)
docker-compose up -d

# Acessar OpenWebUI
# http://localhost:8080
```

## ğŸ’¬ Exemplo de uso

```bash
============================================================
ğŸ”§ CQL AI Agent - Assistente de Reparos Residenciais
============================================================

Inicializando o agente...


âœ… Agente inicializado com sucesso!

ğŸ’¡ Dica: O agente tentarÃ¡ ajudÃ¡-lo atÃ© 3 vezes antes de sugerir um profissional

ğŸ“ Comandos: 'sair' para encerrar | 'novo' para um novo problema

ğŸ‘¤ VocÃª: Como posso consertar uma torneira que estÃ¡ pingando?

ğŸ¤– Agente: Para consertar uma torneira pingando, siga estes passos:

1. **Feche o registro de Ã¡gua** da torneira
2. Abra a torneira para liberar pressÃ£o restante
3. Remova o cabo da torneira
4. Desatarraxe a peÃ§a de vedaÃ§Ã£o
5. Substitua o anel de borracha (O-ring) ou a vÃ¡lvula
6. Remonte tudo na ordem inversa
7. Abra o registro novamente

âš ï¸ **SeguranÃ§a**: Se nÃ£o se sentir confortÃ¡vel, chame um encanador!

O problema foi resolvido? Responda com 'sim' ou 'nÃ£o'.

ğŸ‘¤ VocÃª: 
```

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python** - Linguagem de programaÃ§Ã£o
- **UV** - Gerenciador de pacotes e ambientes virtuais
- **LangChain** - Framework para construÃ§Ã£o de aplicaÃ§Ãµes com LLMs
- **LangChain-Ollama** - IntegraÃ§Ã£o do LangChain com Ollama
- **Pydantic** - ValidaÃ§Ã£o de dados
- **Ollama** - ExecuÃ§Ã£o local de modelos LLM
- **Docker** - ContainerizaÃ§Ã£o do Ollama

## ğŸ“ Estrutura do Projeto

```text
cql-agent/
â”œâ”€â”€ agent.py              # CÃ³digo principal do agente
â”œâ”€â”€ prompts/              # MÃ³dulo de prompts organizados
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py
â”‚   â”œâ”€â”€ states.py
â”‚   â”œâ”€â”€ messages.py
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ rag/                  # MÃ³dulo RAG
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ loader.py         # Carrega e processa PDFs
â”‚   â”œâ”€â”€ vectorstore.py    # Gerencia ChromaDB
â”‚   â””â”€â”€ retriever.py      # Busca documentos
â”œâ”€â”€ tools/                # Ferramentas do agente
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ web_search.py     # Busca web (DuckDuckGo)
â”œâ”€â”€ api/                  # API REST (Fase 4)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ app.py            # Flask API + Swagger
â”œâ”€â”€ openwebui/            # IntegraÃ§Ã£o OpenWebUI
â”‚   â””â”€â”€ pipe.py           # Pipe Function
â”œâ”€â”€ scripts/              # Scripts auxiliares
â”‚   â””â”€â”€ setup_rag.py      # Processa PDFs e cria base
â”œâ”€â”€ docs/                 # DocumentaÃ§Ã£o detalhada
â”‚   â”œâ”€â”€ FASE_2_COMPLETA.md
â”‚   â”œâ”€â”€ FASE_3_COMPLETA.md
â”‚   â”œâ”€â”€ FASE_4_COMPLETA.md
â”‚   â””â”€â”€ README_API.md
â”œâ”€â”€ pdfs/                 # PDFs de conhecimento (adicionar aqui)
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ chroma_db/            # Base vetorial (gerado automaticamente)
â”œâ”€â”€ docker-compose.yml    # Deploy completo (Ollama + API + OpenWebUI)
â”œâ”€â”€ Dockerfile.api        # Docker para API
â”œâ”€â”€ test_api.py           # Testes da API
â”œâ”€â”€ pyproject.toml        # DependÃªncias
â””â”€â”€ README.md             # Este arquivo
```

## ğŸ”„ Status do Projeto

- âœ… **Fase 1**: Agente bÃ¡sico (ConcluÃ­da)
- âœ… **Fase 2**: RAG com base de conhecimento (ConcluÃ­da)
- âœ… **Fase 3**: Busca web com DuckDuckGo (ConcluÃ­da)
- âœ… **Fase 4**: API REST + OpenWebUI (ConcluÃ­da)

## ğŸ“š DocumentaÃ§Ã£o Adicional

- [API REST](docs/README_API.md) - Guia completo da API Flask
- [Fase 2 - RAG](docs/FASE_2_COMPLETA.md) - ImplementaÃ§Ã£o do RAG
- [Fase 3 - Web Search](docs/FASE_3_COMPLETA.md) - Busca web
- [Fase 4 - OpenWebUI](docs/FASE_4_COMPLETA.md) - API + Interface web

## ğŸ› Troubleshooting

### Erro de conexÃ£o com Ollama

```bash
âŒ Erro: Connection refused
```

**SoluÃ§Ã£o**: Certifique-se que o Ollama estÃ¡ rodando:

```bash
docker-compose ps
docker-compose up -d
```

### Modelo nÃ£o encontrado

```bash
âŒ Erro: model 'qwen2.5:3b' not found
```

**SoluÃ§Ã£o**: Baixe o modelo:

```bash
docker exec -it ollama ollama pull qwen2.5:3b
```

## ğŸ“ LicenÃ§a

Este projeto Ã© de cÃ³digo aberto e estÃ¡ disponÃ­vel sob a licenÃ§a MIT.
